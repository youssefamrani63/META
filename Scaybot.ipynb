{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youssefamrani63/META/blob/main/Scaybot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z58bJwkZEq2b"
      },
      "source": [
        "### **INSTALL DEPENDENCIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar28Le0_EoSW",
        "outputId": "6ba7b711-12dc-41d5-e221-bd257b4caf29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.17.1-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured\n",
            "  Downloading unstructured-0.13.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-5.3.0-py3-none-any.whl (21 kB)\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.47-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting unstructured-client<=0.18.0 (from unstructured)\n",
            "  Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting curl-cffi>=0.6.2 (from duckduckgo-search)\n",
            "  Downloading curl_cffi-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.2->duckduckgo-search) (1.16.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Collecting packaging>=19.1 (from build>=1.0.3->chromadb)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Collecting dataclasses-json-speakeasy>=0.5.11 (from unstructured-client<=0.18.0->unstructured)\n",
            "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client<=0.18.0->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from unstructured-client<=0.18.0->unstructured)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12.0->curl-cffi>=0.6.2->duckduckgo-search) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: google-search-results, pypika, langdetect\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=c676f4436ee7cf6afc3848c89e4bf357b0e23637f7d81b7a351c11a51d739267\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=f0daf0f3afe427deb1c51de73085bd815820138442809bca88225726f207420f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=a566626c3a14b0318aa2e87b1207c42d895f64e59f37aea6000e18b515b7f75a\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built google-search-results pypika langdetect\n",
            "Installing collected packages: pypika, monotonic, mmh3, filetype, websockets, uvloop, rapidfuzz, python-magic, python-iso639, python-dotenv, pulsar-client, packaging, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, langdetect, jsonpointer, jsonpath-python, importlib-metadata, humanfriendly, httptools, h11, emoji, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, marshmallow, jsonpatch, httpcore, google-search-results, curl-cffi, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, httpx, fastapi, duckduckgo-search, dataclasses-json-speakeasy, dataclasses-json, unstructured-client, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, openai, langchain-core, unstructured, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-community, langchain, chromadb\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 curl-cffi-0.6.2 dataclasses-json-0.6.4 dataclasses-json-speakeasy-0.5.11 deprecated-1.2.14 duckduckgo-search-5.3.0 emoji-2.11.0 fastapi-0.110.1 filetype-1.2.0 google-search-results-2.4.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.0.0 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-2.4 kubernetes-29.0.0 langchain-0.1.16 langchain-community-0.0.32 langchain-core-0.1.42 langchain-text-splitters-0.0.1 langdetect-1.0.9 langsmith-0.1.47 marshmallow-3.21.1 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.17.3 openai-1.17.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.0 overrides-7.7.0 packaging-23.2 posthog-3.5.0 pulsar-client-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.8.1 starlette-0.37.2 tiktoken-0.6.0 typing-inspect-0.9.0 unstructured-0.13.2 unstructured-client-0.18.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install langchain openai chromadb tiktoken unstructured requests duckduckgo-search google-search-results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwY_wkuoFIgk",
        "outputId": "07197585-0f89-4d61-81a9-ec09d82297e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain.document_loaders (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain.document_loaders\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain.document_loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kSZuV-DxFX6t"
      },
      "outputs": [],
      "source": [
        "!pip3 install --upgrade --quiet  youtube_search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5NmORTvFcia",
        "outputId": "d8608b69-ef15-4b90-f8a2-99107ebc9460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting libmagic\n",
            "  Downloading libmagic-1.0.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: libmagic\n",
            "  Building wheel for libmagic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libmagic: filename=libmagic-1.0-py3-none-any.whl size=4270 sha256=f7a71965f2e42d928b633685ed25d2a9e5e35a22517d5b5fed01622aee75f03c\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/ce/d8/099fbd4dbfa5da5596a39eee8a17d2e1bcc29006c07d3563b7\n",
            "Successfully built libmagic\n",
            "Installing collected packages: libmagic\n",
            "Successfully installed libmagic-1.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement poppler (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for poppler\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting tesseract\n",
            "  Downloading tesseract-0.1.3.tar.gz (45.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tesseract\n",
            "  Building wheel for tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract: filename=tesseract-0.1.3-py3-none-any.whl size=45562552 sha256=3186ca6f44be80baa7ad22b3db8da1117d2ff5bf41190bed35c8bba2f010be6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/c9/aa/698c579693e83fdda9ad6d6f0d8f61ed986e27925ef576f109\n",
            "Successfully built tesseract\n",
            "Installing collected packages: tesseract\n",
            "Successfully installed tesseract-0.1.3\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement libxml2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for libxml2\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement libxslt (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for libxslt\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: -c: line 1: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 2: syntax error: unexpected end of file\n",
            "/bin/bash: line 1: import: command not found\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `'punkt''\n",
            "/bin/bash: -c: line 1: `nltk.download('punkt')'\n"
          ]
        }
      ],
      "source": [
        "!pip install libmagic\n",
        "!pip install poppler\n",
        "!pip install tesseract\n",
        "!pip install libxml2\n",
        "!pip install libxslt\n",
        "!pip install --upgrade --quiet  \"unstructured[all-docs]\n",
        "!import nltk\n",
        "!nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccwt6UsEFzGj"
      },
      "source": [
        "### **API KEYS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dxd3SOxyF2et"
      },
      "outputs": [],
      "source": [
        "OPENAI_APIKEY = \"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\"\n",
        "SERPAPI_APIKEY = \"0b275fe3e19932b564a527c6f8722e639e60e92709dad761ba978776bb4b1206\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "id": "MxE2FNY5_kQh",
        "outputId": "e75d4d32-8a47-4273-a4ee-6695bf3d572e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.42)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.17.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.1.47)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.6.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain_openai) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n",
            "Installing collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai_tools\n"
      ],
      "metadata": {
        "id": "qoSr7v-LOmKI",
        "outputId": "87c34158-8c0e-4fcd-ee07-9f4fcf18de3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai_tools\n",
            "  Downloading openai_tools-0.0.0.1-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: openai>=0.27.4 in /usr/local/lib/python3.10/dist-packages (from openai_tools) (1.17.1)\n",
            "Requirement already satisfied: backoff>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from openai_tools) (2.2.1)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from openai_tools) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.1.2->openai_tools) (2.1.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.4->openai_tools) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=0.27.4->openai_tools) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.4->openai_tools) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.4->openai_tools) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.4->openai_tools) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.4->openai_tools) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.4->openai_tools) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=0.27.4->openai_tools) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=0.27.4->openai_tools) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=0.27.4->openai_tools) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=0.27.4->openai_tools) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.27.4->openai_tools) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=0.27.4->openai_tools) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=0.27.4->openai_tools) (2.16.3)\n",
            "Installing collected packages: openai_tools\n",
            "Successfully installed openai_tools-0.0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blme9uwCFkXI"
      },
      "source": [
        "### **IMPORT LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fxMRDyvaFqiW"
      },
      "outputs": [],
      "source": [
        " # used to load text\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# used to create the retriever\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# used to create the retrieval tool\n",
        "from langchain.tools import Tool\n",
        "\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "\n",
        "# used to create the memory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# used to create the prompt template\n",
        "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.prompts import MessagesPlaceholder\n",
        "from langchain_community.document_loaders import UnstructuredFileLoader\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "\n",
        "# used to create the agent executor\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_community.tools import YouTubeSearchTool\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from typing import List\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XFg1Kfo0GB57"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_APIKEY\n",
        "os.environ[\"SERPAPI_API_KEY\"] = SERPAPI_APIKEY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pEmJYUpGDdY"
      },
      "source": [
        "### **SCAYBOT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXvUFfbWGOBx"
      },
      "source": [
        "### *LOADER FILES*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H1uEfF4JGRvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4961e8-47f9-41a1-c2c4-6b4cae342bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "#loader_dic = DirectoryLoader(\"/content/sample_data/Scaylab\")\n",
        "#loader_dic = TextLoader(\"/content/sample_data/Fiche BRINNOVAT.txt\")\n",
        "#data = loader_dic.load()\n",
        "loader = UnstructuredFileLoader(\"/content/sample_data/Startup X-Point.txt\")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf591dx2Gha4"
      },
      "source": [
        "### *CONNEXION TO PYMONGO DB*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEP8-l7aGerg"
      },
      "outputs": [],
      "source": [
        "# Connexion à la base de données MongoDB\n",
        "#client = pymongo.MongoClient(\"mongodb://localhost\", 27017)  # Remplacez par vos propres informations de connexion\n",
        "#db = client[\"Scaylab\"]\n",
        "#collection = db[\"test\"]\n",
        "#data = collection.find()  # Vous pouvez adapter cette requête selon vos besoins\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGeUAbaXGrke"
      },
      "source": [
        "### *DATA SPLIT AND EMBEDDING*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4Y62ch0WG3HY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3f9779-b6e7-4458-e968-e84666dd63bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "splits = text_splitter.split_documents(data)\n",
        "\n",
        "# Embedding my data with chroma\n",
        "embedding = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits, embedding=embedding, collection_name=\"startup-data\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB6pM-jsIGUC",
        "outputId": "9858e6d2-13a9-420d-f8f7-815042039e6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Startup : X-Point\\n\\nDescription : X-Point a pour mission première de contribuer à façonner l'avenir du travail. Elle offre des solutions de gestion du travail hybride (Flex office et télétravail) et de planification des déplacements professionnels.\\n\\nSecteur : Worktech\\n\\nTags : Worktech, Hybrid Working, Business Travel\\n\\nObjectif 1 :\\n\\nTitre : Echange autour de l'expertise ESG\\n\\nDescription : Discussion approfondie et constructive sur l'expertise en matière d'ESG (Environnement, Social, Gouvernance), en mettant l'accent sur les pratiques durables, les performances financières et l'impact social des entreprises.\\n\\nObjectif 2 :\\n\\nTitre : Gestion de produit et méthodologies agiles\\n\\nDescription : Aborder les concepts fondamentaux de la gestion de produit, y compris la définition des objectifs, la création de roadmaps, explorer les principes clés des méthodologies agiles en mettant l'accent sur la collaboration, l'itération rapide et l'adaptabilité aux changements.\\n\\nObjectif 3 :\\n\\nTitre : Levée de fonds & développement\\n\\nDescription : Déterminer la valeur de l'entreprise, en prenant en compte divers paramètres spécifiques au secteur et au stade de développement, définir les objectifs financiers et les stratégies de collecte de fonds, afin d'optimiser les chances de réussite dans la recherche de financement.\\n\\nObjectif 4 :\\n\\nTitre : Stratégies de Pitch Investisseur\\n\\nDescription : Mettre en place un processus structuré pour comprendre les besoins et les attentes des investisseurs, identifier les points clés à inclure dans le pitch, et affiner le message pour maximiser l'impact.\", metadata={'source': '/content/sample_data/Startup X-Point.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GCkj-_dHHpp"
      },
      "source": [
        "### SCAYBOT TOOLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FeHV-i9hHKzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b8bcfeb-bfeb-4a58-dca6-5706a42245ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm_temperature = 0\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=llm_temperature, openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "personal_data = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=vectordb.as_retriever()\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "personal_data_tool = Tool(\n",
        "    name=\"startup-data\",\n",
        "    func=personal_data.run,\n",
        "    description=\"useful for when you need to search insights and recommandation based on the given data . \",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "search = SerpAPIWrapper()\n",
        "\n",
        "serpapi_tool = Tool(\n",
        "    name=\"Search\",\n",
        "    func=search.run,\n",
        "    description=\"useful for when you need to search insights and recommandation based on the given data\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# setting up memory\n",
        "memory_key = \"history\"\n",
        "memory = ConversationBufferMemory(memory_key=memory_key, return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(temperature=0)\n"
      ],
      "metadata": {
        "id": "HmIBAyAz_3Oy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip upgrade langchain"
      ],
      "metadata": {
        "id": "3AcDy1M3PyLE",
        "outputId": "ef3c628a-6b67-4cc1-8da9-545c7c5a2097",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"upgrade\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-prompts\n"
      ],
      "metadata": {
        "id": "vvjnHUv_PL4H",
        "outputId": "0f88b75a-bf89-47ac-c336-01ca78ffb0fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain-prompts (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain-prompts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QzitCHEUPL-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import Chain, Question\n",
        "from langchain.tools import PersonalDataTool, SerpApiTool, YoutubeSearchTool\n",
        "\n",
        "# Define your recommendation class (same as before)\n",
        "class Recommendation(BaseModel):\n",
        "  llm_answer: str\n",
        "  video_youtube: str\n",
        "  online_courses: str\n",
        "\n",
        "# System message is not directly used in LangChain, but you can keep it for documentation\n",
        "system_message = \"\"\"\n",
        "Do your best to answer the questions about startups.\n",
        "Feel free to use any tools available to look up information.\n",
        "Use always the relevant information to search recommendations.\n",
        "\"\"\"\n",
        "\n",
        "# Define the prompt chain\n",
        "prompt = Chain(\n",
        "  Question(\"What are the sectors and objectives of startup X-point based on the file?\"),\n",
        "  # Call external tools (optional)\n",
        "  # Chain(SerpApiTool(query=\"startup X-point sectors and objectives\")),  # Example tool usage\n",
        "  Question(\"Provide a well-structured and specific recommendation for the startup...\"),  # Use llm_answer from Recommendation\n",
        "  Question(\"As a startup co-pilot, recommend YouTube videos for each objective...\"),  # Use video_youtube from Recommendation\n",
        "  Question(\"As a startup co-pilot, recommend online courses for each objective...\"),  # Use online_courses from Recommendation\n",
        ")\n",
        "\n",
        "# Define the tools (same as before)\n",
        "tools = [PersonalDataTool(), SerpApiTool(), YoutubeSearchTool()]\n",
        "\n",
        "# Create the LangChain instance\n",
        "langchain = OpenAI(prompt=prompt, tools=tools)\n",
        "\n",
        "# Execute the LangChain and get the results\n",
        "result = langchain.run(\n",
        "  data={\"recommandation\": \"Give me recommendations.\"},\n",
        "  handle_parsing_errors=True  # Optional, handle potential parsing errors gracefully\n",
        ")\n",
        "\n",
        "# Access the results from the Recommendation class\n",
        "recommendation = Recommendation(**result)\n",
        "print(f\"LLM Answer: {recommendation.llm_answer}\")\n",
        "print(f\"YouTube Videos: {recommendation.video_youtube}\")\n",
        "print(f\"Online Courses: {recommendation.online_courses}\")\n"
      ],
      "metadata": {
        "id": "8HVHXC2OOD5V",
        "outputId": "f28377b2-3b3b-483e-9af5-5e009f569ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Chain' from 'langchain.prompts' (/usr/local/lib/python3.10/dist-packages/langchain/prompts/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d476d9579b3d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuestion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPersonalDataTool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSerpApiTool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYoutubeSearchTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define your recommendation class (same as before)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Chain' from 'langchain.prompts' (/usr/local/lib/python3.10/dist-packages/langchain/prompts/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain\n"
      ],
      "metadata": {
        "id": "_n7K9bwAVw5H",
        "outputId": "85d52234-2f56-415f-90cb-edec24494e1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.32)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.42)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.47)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Recommendation(BaseModel):\n",
        "    \"\"\"Represents recommendations for a startup.\"\"\"\n",
        "\n",
        "    llm_answer: str = Field(\n",
        "        default=(\n",
        "            \"Provide a well-structured and specific recommendation for the startup based \"\n",
        "            \"on the sectors and objectives given from the file 'startup x-point'. As a \"\n",
        "            \"co-pilot of startups, your recommendation should be concise and brief, \"\n",
        "            \"focusing on delivering a clear and detailed suggestion that aligns with \"\n",
        "            \"the specified sectors and objectives.\"\n",
        "        ),\n",
        "        description=\"A well-structured recommendation considering sectors and objectives.\",\n",
        "    )\n",
        "    video_youtube: List[str] = Field(default_factory=list, description=\"List of YouTube video recommendations with explanations.\")\n",
        "    online_courses: List[str] = Field(default_factory=list, description=\"List of online course recommendations with explanations.\")\n",
        "\n",
        "\n",
        "# File loading and data preparation\n",
        "def process_startup_file(file_path):\n",
        "    loader = UnstructuredFileLoader(file_path)\n",
        "    data = loader.load()\n",
        "\n",
        "    # Split data into manageable chunks (adjust chunk size if needed)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    splits = text_splitter.split_documents(data)\n",
        "\n",
        "    # Embed data using OpenAI embeddings (replace with suitable embedding method if needed)\n",
        "    embedding = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "    vectordb = Chroma.from_documents(\n",
        "        documents=splits, embedding=embedding, collection_name=\"startup-data\"\n",
        "    )\n",
        "\n",
        "    return vectordb\n",
        "\n",
        "# Startup data retrieval tool (using processed data)\n",
        "def retrieve_startup_insights(query, vectordb):\n",
        "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "    personal_data = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
        "    return personal_data.run(query)\n",
        "\n",
        "\n",
        "personal_data_tool = Tool(\n",
        "    name=\"startup-data\",\n",
        "    func=lambda query: retrieve_startup_insights(query, process_startup_file(\"/content/sample_data/Startup X-Point.txt\")),  # Pass processed data\n",
        "    description=\"Searches insights and recommendations based on the startup data file.\",\n",
        ")\n",
        "\n",
        "\n",
        "# Prompt with user input\n",
        "system_message = (\n",
        "    \"Do your best to answer the questions about startups. Feel free to use any tools \"\n",
        "    \"available to look up information. Use the information in the provided startup \"\n",
        "    \"file to generate recommendations.\"\n",
        ")\n",
        "\n",
        "user_prompt = input(\"Enter the path to the startup file (optional, default: 'startup.txt'): \")\n",
        "file_path = user_prompt if user_prompt else \"startup.txt\"\n",
        "prompt_text = f\"{system_message}\\nUse the startup file located at: {file_path}\"\n",
        "prompt = PromptTemplate(template=prompt_text)\n",
        "\n",
        "# Tools\n",
        "tools = [PersonalDataTool(), SerpApiTool(), YoutubeSearchTool()]\n",
        "\n",
        "# LLM and parser\n",
        "llm = OpenAI()  # Assuming OpenAI is your LLM\n",
        "parser = JsonOutputParser(Recommendation())\n",
        "\n",
        "# Chain\n",
        "chain = Chain(prompt, tools, llm, parser)\n",
        "\n",
        "# Execute the chain with user input\n",
        "user_query = \"Give me recommendations.\"\n",
        "try:\n",
        "    result = chain.invoke({\"query\": user_query})\n",
        "    recommendation = Recommendation(**result)\n",
        "    print(f\"LLM Answer: {recommendation.llm_answer}\")\n",
        "    print(f\"YouTube Videos: {recommendation.video_youtube}\")\n",
        "    print(f\"Online Courses: {recommendation.online_courses}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "BUeoTLT4ViKB",
        "outputId": "e29b58a5-701c-48bf-bc41-d91d569220c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path to the startup file (optional, default: 'startup.txt'): /content/sample_data/Startup X-Point.txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'input_variables'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-24f72db13dd4>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_prompt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muser_prompt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"startup.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprompt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{system_message}\\nUse the startup file located at: {file_path}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrorWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROOT_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36mvalidate_variable_names\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_variable_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;34m\"\"\"Validate variable names do not include restricted names.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"stop\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_variables\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             raise ValueError(\n\u001b[1;32m    163\u001b[0m                 \u001b[0;34m\"Cannot have an input variable named 'stop', as it is used internally,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'input_variables'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwjasB4jHSDt"
      },
      "source": [
        "### *SCAYBOT AGENTS AND DEFAULT PROMPT*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "LBHNtwmpHYKm"
      },
      "outputs": [],
      "source": [
        "# setting default prompt\n",
        "system_message = SystemMessage(\n",
        "    content=(\n",
        "        \"Do your best to answer the questions about startups. \"\n",
        "        \"Feel free to use any tools available to look up \"\n",
        "        \"Use always the relevant information to search recommandations\"\n",
        "))\n",
        "\n",
        "prompt = OpenAIFunctionsAgent.create_prompt(\n",
        "    system_message=system_message,\n",
        "    extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)]\n",
        ")\n",
        "\n",
        "\n",
        "tools = [personal_data_tool,serpapi_tool,YouTubeSearchTool()]\n",
        "\n",
        "agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "#result = agent_executor({\"input\": \"Hey, Are you ready for work?\"})\n",
        "\n",
        "#prompt = None\n",
        "\n",
        "#agent = initialize_agent(\n",
        "#    tools=tools,\n",
        "#    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "#    llm=llm,\n",
        "#    memory=memory,\n",
        "#    verbose=True,\n",
        "#    handle_parsing_errors=True\n",
        "#)\n",
        "\n",
        "prompt = None\n",
        "post_prompt = f\". Use your tools to fetch the given data from X-point ,search and finds a good insights and recommandations for Startups \"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Used for embedding and retrieval\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Used for creating tools\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Used for loading data\n",
        "from langchain_community.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "# Used for LLM and parsing\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Used for YouTube search\n",
        "from langchain_community.tools import YouTubeSearchTool\n",
        "\n",
        "# Define the recommendation data structure\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Recommendation(BaseModel):\n",
        "    llm_answer: str = Field(\n",
        "        default=(\n",
        "            \"Provide a well-structured and specific recommendation for the startup based \"\n",
        "            \"on the sectors and objectives given from the file 'startup x-point'. As a \"\n",
        "            \"co-pilot of startups, your recommendation should be concise and brief, \"\n",
        "            \"focusing on delivering a clear and detailed suggestion that aligns with \"\n",
        "            \"the specified sectors and objectives.\"\n",
        "        ),\n",
        "        description=\"A well-structured recommendation considering sectors and objectives.\",\n",
        "    )\n",
        "    video_youtube: List[str] = Field(default_factory=list, description=\"List of YouTube video recommendations with explanations.\")\n",
        "    online_courses: List[str] = Field(default_factory=list, description=\"List of online course recommendations with explanations.\")\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_APIKEY  # Replace with your OpenAI API key\n",
        "os.environ[\"SERPAPI_API_KEY\"] = SERPAPI_APIKEY  # Replace with your SerpAPI API key if needed\n",
        "\n",
        "# Load data from the startup file\n",
        "loader = UnstructuredFileLoader(\"/content/sample_data/Startup X-Point.txt\")\n",
        "data = loader.load()\n",
        "\n",
        "# Split data into chunks for efficient processing\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "splits = text_splitter.split_documents(data)\n",
        "\n",
        "# Embed data using OpenAI embeddings\n",
        "embedding = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits, embedding=embedding, collection_name=\"startup-data\"\n",
        ")\n",
        "\n",
        "# Define the LLM and parser\n",
        "llm = ChatOpenAI(temperature=0)  # Adjust temperature for more diversity\n",
        "parser = JsonOutputParser(pydantic_object=Recommendation)\n",
        "\n",
        "# Define the retrieval tool using the processed data\n",
        "def retrieve_startup_insights(query, vectordb):\n",
        "    personal_data = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
        "    return personal_data.run(query)\n",
        "\n",
        "personal_data_tool = Tool(\n",
        "    name=\"startup-data\",\n",
        "    func=lambda query: retrieve_startup_insights(query, vectordb),  # Pass processed data\n",
        "    description=\"Searches insights and recommendations based on the startup data file.\",\n",
        ")\n",
        "\n",
        "# Define the YouTube search tool\n",
        "youtube_search_tool = YouTubeSearchTool()\n",
        "\n",
        "# Define the online course search tool using SerpAPI (example)\n",
        "def search_online_courses(query):\n",
        "    search = SerpAPIWrapper()\n",
        "    results = search.run(query=f\"online courses on {query}\")\n",
        "    course_recommendations = []\n",
        "    for result in results[:3]:  # Limit to top 3 results\n",
        "        course_recommendations.append(f\"- {result['title']}\")  # Extract title only (modify for more details)\n",
        "    return \"\\n\".join(course_recommendations) or \"No relevant online courses found.\"\n",
        "\n",
        "online_courses_tool = Tool(\n",
        "    name=\"online_courses\",\n",
        "    func=search_online_courses,\n",
        "    description=\"Searches for online courses based on startup information.\",\n",
        ")\n",
        "# Define the prompt template (corrected)\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"Based on the information in the 'Startup X-Point' file:\n",
        "\n",
        "    1. LLM Answer: {personal_data_tool.run(query='Summarize the key points about the startup.')}\n",
        "\n",
        "    2. Recommendations:\n",
        "\n",
        "        * Youtube Videos:\n",
        "            {youtube_search_tool.run(query='Find relevant YouTube videos for the startup.')}\n",
        "\n",
        "        * Online Courses:\n",
        "            {online_courses_tool.run(query='Find relevant online courses for the startup based on its goals.')}\n",
        "    \"\"\",\n",
        "    # Update input_variables to reflect actual order\n",
        "    input_variables=[\"personal_data_tool.run\", \"youtube_search_tool.run\", \"online_courses_tool.run\"],\n",
        "    partial_variables={\n",
        "        \"personal_data_tool\": personal_data_tool,\n",
        "        \"youtube_search_tool\": youtube_search_tool,\n",
        "        \"online_courses_tool\": online_courses_tool,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# Create the chain and execute\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# Execute the entire chain (no input needed)\n",
        "# Input dictionary with placeholders filled (modify queries as needed)\n",
        "input_dict = {\n",
        "    \"personal_data_tool.run\": \"Summarize the key points about the startup.\",\n",
        "    \"youtube_search_tool.run\": \"Find relevant YouTube videos for the startup based on its sectors and objectives.\",\n",
        "    \"online_courses_tool.run\": \"Find relevant online courses for the startup based on its goals.\",\n",
        "}\n",
        "\n",
        "# Execute the entire chain with input dictionary\n",
        "result = chain.invoke(input_dict)\n",
        "\n",
        "# Print the structured recommendation\n",
        "recommendation = Recommendation(**result)\n",
        "print(f\"**Recommendation for Startup X-Point:**\\n\")\n",
        "print(f\"1. LLM Answer:\\n{recommendation.llm_answer}\\n\")\n",
        "print(f\"1. LLM Answer:\\n{recommendation.Online_Courses}\\n\")\n",
        "print(f\"1. LLM Answer:\\n{recommendation.Youtube_Videos}\\n\")\n"
      ],
      "metadata": {
        "id": "TnxmmgruXbRv",
        "outputId": "509cc74c-ab56-47ca-a676-54e9dd953acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Input to PromptTemplate is missing variables {\"youtube_search_tool.run(query=\\'Find relevant YouTube videos for the startup.\\')\", \"online_courses_tool.run(query=\\'Find relevant online courses for the startup based on its goals.\\')\", \"personal_data_tool.run(query=\\'Summarize the key points about the startup.\\')\"}.  Expected: [\"online_courses_tool.run(query=\\'Find relevant online courses for the startup based on its goals.\\')\", \"personal_data_tool.run(query=\\'Summarize the key points about the startup.\\')\", \"youtube_search_tool.run(query=\\'Find relevant YouTube videos for the startup.\\')\"] Received: [\\'personal_data_tool.run\\', \\'youtube_search_tool.run\\', \\'online_courses_tool.run\\']'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-09ef3d776bbc>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# Execute the entire chain with input dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m# Print the structured recommendation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m                 input = step.invoke(\n\u001b[0m\u001b[1;32m   2500\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m                     \u001b[0;31m# mark each step as a child run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         return self._call_with_config(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1623\u001b[0m             output = cast(\n\u001b[1;32m   1624\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1626\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPromptValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0m_inner_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_inner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;34mf\"Input to {self.__class__.__name__} is missing variables {missing}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;34mf\" Expected: {self.input_variables}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Input to PromptTemplate is missing variables {\"youtube_search_tool.run(query=\\'Find relevant YouTube videos for the startup.\\')\", \"online_courses_tool.run(query=\\'Find relevant online courses for the startup based on its goals.\\')\", \"personal_data_tool.run(query=\\'Summarize the key points about the startup.\\')\"}.  Expected: [\"online_courses_tool.run(query=\\'Find relevant online courses for the startup based on its goals.\\')\", \"personal_data_tool.run(query=\\'Summarize the key points about the startup.\\')\", \"youtube_search_tool.run(query=\\'Find relevant YouTube videos for the startup.\\')\"] Received: [\\'personal_data_tool.run\\', \\'youtube_search_tool.run\\', \\'online_courses_tool.run\\']'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_prompts(prompts):\n",
        "    \"\"\"Processes a list of prompts, calls the agent, and combines outputs.\"\"\"\n",
        "    output = {}  # Dictionary to store combined outputs\n",
        "    for prompt in prompts:  # Iterate through each prompt in the list\n",
        "        agent_response = agent(prompt)  # Call the agent function with the current prompt\n",
        "        output_key = prompt.split(\" \", 1)[0].lower()  # Extract keyword from prompt\n",
        "        output[output_key] = agent_response  # Store response under keyword\n",
        "\n",
        "    return output\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    prompts = [\n",
        "        \"As a startup co-pilot, based on the sectors and goals of startup x-point, recommend YouTube videos for each objective to enhance the startup's performance...\",\n",
        "        \"As a startup co-pilot, based on the sectors and goals of startup x-point, recommend online courses for each objective to enhance the startup's performance...\",\n",
        "        \"As a startup co-pilot, based on the sectors and goals of startup x-point, recommend blogs for each objective to enhance the startup's performance...\",\n",
        "    ]\n",
        "\n",
        "    # Process prompts and get combined output\n",
        "    combined_output = process_prompts(prompts)\n",
        "\n",
        "    # Print the combined output in a user-friendly format\n",
        "    print(\"**Recommendations for Startup X-Point:**\")\n",
        "    for key, value in combined_output.items():\n",
        "        print(f\"- {key.capitalize()}: {value}\")\n",
        "\n",
        "    # Example usage with command-line arguments (optional)\n",
        "    if len(sys.argv) > 1:\n",
        "        user_prompt = sys.argv[1]\n",
        "        print(f\"\\n**Output for user prompt:** {agent(user_prompt)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "7o2DphO7Qqfk",
        "outputId": "2e2356f9-ac9f-4605-e676-c44707901fbf"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'RunnableSequence' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-52d0b5befca9>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Process prompts and get combined output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mcombined_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Print the combined output in a user-friendly format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-52d0b5befca9>\u001b[0m in \u001b[0;36mprocess_prompts\u001b[0;34m(prompts)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# Dictionary to store combined outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Iterate through each prompt in the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0magent_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call the agent function with the current prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moutput_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Extract keyword from prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_response\u001b[0m  \u001b[0;31m# Store response under keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'RunnableSequence' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# System message with default prompt\n",
        "system_message = SystemMessage(\n",
        "    content=(\n",
        "        \"Do your best to answer the questions about startups. \"\n",
        "        \"Feel free to use any tools available to look up information. \"\n",
        "        \"Use always the relevant information to search recommendations.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Define placeholders for the three prompts (replace with actual content)\n",
        "video_youtube_placeholder = MessagesPlaceholder(variable_name=\"video_youtube_prompt\")\n",
        "online_courses_placeholder = MessagesPlaceholder(variable_name=\"online_courses_prompt\")\n",
        "blogs_placeholder = MessagesPlaceholder(variable_name=\"blogs_prompt\")\n",
        "\n",
        "# Create the main prompt with placeholders\n",
        "prompt = OpenAIFunctionsAgent.create_prompt(\n",
        "    system_message=system_message,\n",
        "    extra_prompt_messages=[\n",
        "        video_youtube_placeholder,\n",
        "        online_courses_placeholder,\n",
        "        blogs_placeholder,\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Define the three prompts for video, courses, and blogs (replace with actual content)\n",
        "video_youtube_prompt = f\"As a startup co-pilot, based on the sectors and goals of startup x-point, recommend YouTube videos for each objective to enhance the startup's performance. Please provide the blog URL and a brief explanation for each recommendation in the following format: URL YouTube video - Explanation. Ensure that each YouTube video link is functional by testing it before displaying it. If the YouTube video link is not working, please attempt to find a valid blog for the recommendation. Please note that your recommendations should be relevant to the specific sectors and goals of x-point, and the explanations should clearly illustrate how each YouTube video can contribute to improving the startup. Your recommendations should cover a diverse range of topics and resources to support the startup's growth and development.\"\n",
        "\n",
        "online_courses_prompt = f\"As a startup co-pilot, based on the sectors and goals of startup x-point, recommend online courses for each objective to enhance the startup's performance. Please provide the online courses URL and a brief explanation for each recommendation in the following format: URL online_courses - Explanation. Ensure that each online courses link is functional by testing it before displaying it. If the online courses link is not working, please attempt to find a valid online courses for the recommendation. Please note that your recommendations should be relevant to the specific sectors and goals of x-point, and the explanations should clearly illustrate how each online courses can contribute to improving the startup. Your recommendations should cover a diverse range of topics and resources to support the startup's growth and development.\"\n",
        "\n",
        "blogs_prompt = f\"As a startup co-pilot, based on the sectors and goals of startup x-point, recommend blogs for each objective to enhance the startup's performance. Please provide the blog URL and a brief explanation for each recommendation in the following format: URL blog - Explanation. Ensure that each blog link is functional by testing it before displaying it. If the blog link is not working, please attempt to find a valid blog for the recommendation. Please note that your recommendations should be relevant to the specific sectors and goals of x-point, and the explanations should clearly illustrate how each blog can contribute to improving the startup. Your recommendations should cover a diverse range of topics and resources to support the startup's growth and development.\"\n",
        "\n",
        "# Tools (replace with your actual implementations)\n",
        "tools = [personal_data_tool, serpapi_tool, YouTubeSearchTool()]\n",
        "\n",
        "# Create the OpenAI agent with tools and prompt\n",
        "agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)\n",
        "\n",
        "# Agent executor (replace with your actual implementation)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    memory=memory,  # Assuming you have a memory object\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "# Main loop for user interaction\n",
        "while True:\n",
        "    if not prompt:\n",
        "        prompt = input(\"\\033[31m\\r\\nPrompt: \\033[0m\")\n",
        "    if prompt in ['quit', 'q', 'exit']:\n",
        "        sys.exit()\n",
        "\n",
        "    # Modify the prompt with the chosen post-prompt (replace with your logic)\n",
        "    if \"video_youtube\" in prompt.lower():\n",
        "        post_prompt = video_youtube_prompt\n",
        "    elif \"online_courses\" in prompt.lower():\n",
        "        post_prompt = online_courses_prompt\n",
        "\n"
      ],
      "metadata": {
        "id": "oUEoFcQYpP04",
        "outputId": "e655d3d0-2637-4c20-88bf-984a0d64ddaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ChatPromptTemplate' object has no attribute 'lower'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-29844fcf8056>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Modify the prompt with the chosen post-prompt (replace with your logic)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"video_youtube\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mpost_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_youtube_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m\"online_courses\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ChatPromptTemplate' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSBob7CuHvqw"
      },
      "source": [
        "### *AGENT EXECUTION*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_s4mYWG9Hy7-",
        "outputId": "060b546e-4767-4b98-b8a4-3155a091c382"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `startup-data` with `X-point`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mX-Point est une startup qui vise à façonner l'avenir du travail en offrant des solutions de gestion du travail hybride (Flex office et télétravail) et de planification des déplacements professionnels. Son secteur d'activité est le Worktech, et elle se concentre sur des thèmes tels que le travail hybride, les déplacements professionnels et les technologies liées au travail. De plus, elle aborde des sujets tels que l'expertise ESG (Environnement, Social, Gouvernance) et la gestion de produit avec des méthodologies agiles.\u001b[0m\u001b[32;1m\u001b[1;3m### Insights for X-Point:\n",
            "\n",
            "1. **Hybrid Work Management**: X-Point focuses on shaping the future of work by providing solutions for hybrid work management, including flexible office arrangements and remote work options. This aligns with the evolving work trends towards flexibility and adaptability in the workplace.\n",
            "\n",
            "2. **Worktech Sector**: Operating in the Worktech sector positions X-Point at the intersection of technology and workplace solutions. This sector focuses on innovative technologies and solutions that enhance work environments and productivity.\n",
            "\n",
            "3. **ESG Expertise**: X-Point's emphasis on ESG (Environmental, Social, Governance) expertise indicates a commitment to sustainability and responsible business practices. This expertise can help the startup differentiate itself in the market and attract socially conscious clients and investors.\n",
            "\n",
            "4. **Agile Product Management**: The adoption of agile methodologies for product management demonstrates X-Point's commitment to flexibility, collaboration, and iterative development processes. This approach enables the startup to respond quickly to market changes and customer feedback.\n",
            "\n",
            "### Recommendations for X-Point:\n",
            "\n",
            "1. **Market Expansion**: Explore opportunities to expand services beyond hybrid work management to include additional Worktech solutions such as workspace optimization, digital workplace tools, or employee engagement platforms. This diversification can help X-Point reach a broader audience and increase its market presence.\n",
            "\n",
            "2. **Partnerships and Collaborations**: Foster partnerships with coworking spaces, technology providers, or travel agencies to enhance service offerings and provide comprehensive solutions for hybrid work management and business travel planning. Collaborations can leverage complementary expertise and resources to drive innovation and growth.\n",
            "\n",
            "3. **ESG Integration**: Develop a robust ESG framework and sustainability strategy to embed environmental and social considerations into business operations. Implementing ESG practices can enhance brand reputation, attract ESG-focused clients and investors, and contribute to long-term sustainability goals.\n",
            "\n",
            "4. **Agile Training and Development**: Provide training and resources on agile product management for teams to improve collaboration, innovation, and product delivery efficiency. Investing in agile training can enhance team performance, streamline product development processes, and foster a culture of continuous improvement.\n",
            "\n",
            "By implementing these recommendations and leveraging the identified insights, X-Point can strengthen its position in the Worktech sector, drive innovation, and achieve sustainable growth aligned with its goals and objectives.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `startup-data` with `X-point`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mX-Point est une startup qui vise à façonner l'avenir du travail en offrant des solutions de gestion du travail hybride (Flex office et télétravail) et de planification des déplacements professionnels. Elle opère dans le secteur du Worktech et se concentre sur des thèmes tels que le travail hybride, les déplacements professionnels et les technologies liées au travail.\u001b[0m\u001b[32;1m\u001b[1;3m### Recommendation for X-Point:\n",
            "\n",
            "**Objective**:\n",
            "1. **Hybrid Work Management**: X-Point aims to provide solutions for hybrid work management, including flexible office arrangements and remote work options.\n",
            "   \n",
            "2. **Worktech Sector Focus**: The startup operates in the Worktech sector, focusing on innovative technologies and solutions for work environments.\n",
            "\n",
            "### Recommendation:\n",
            "To align with X-Point's objectives in hybrid work management and the Worktech sector, it is recommended to:\n",
            "\n",
            "**Develop Integrated Worktech Solutions**: Create integrated Worktech solutions that combine hybrid work management tools with innovative technologies for workspace optimization, employee engagement, and seamless business travel planning. This approach will differentiate X-Point in the market and provide comprehensive solutions for modern work environments.\n",
            "\n",
            "By focusing on developing integrated Worktech solutions that cater to the evolving needs of hybrid work environments, X-Point can enhance its position in the Worktech sector and offer valuable solutions for businesses looking to optimize their workspaces and adapt to flexible work arrangements.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `startup-data` with `X-point`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mX-Point est une startup qui se concentre sur la gestion du travail hybride (Flex office et télétravail) et la planification des déplacements professionnels dans le secteur du Worktech. Ses objectifs incluent des échanges sur l'expertise ESG (Environnement, Social, Gouvernance) et la gestion de produit avec des méthodologies agiles.\u001b[0m\u001b[32;1m\u001b[1;3m### Recommendations for X-Point:\n",
            "\n",
            "1. **Integrated Worktech Solutions**: Develop integrated solutions that combine hybrid work management tools with innovative technologies for workspace optimization and seamless business travel planning. This will differentiate X-Point in the Worktech sector and provide comprehensive solutions for modern work environments.\n",
            "\n",
            "2. **ESG Framework Implementation**: Create and implement a robust ESG framework that integrates sustainability practices into all aspects of the business. This will demonstrate a commitment to environmental and social responsibility, attracting socially conscious clients and investors.\n",
            "\n",
            "3. **Agile Product Development Training**: Provide training on agile methodologies for product development teams to enhance collaboration, adaptability, and continuous improvement. This will streamline product development processes and ensure alignment with agile principles.\n",
            "\n",
            "4. **Partnerships and Collaborations**: Foster partnerships with coworking spaces, technology providers, and travel agencies to enhance service offerings and provide end-to-end solutions for hybrid work management and business travel planning. Collaborations can leverage complementary expertise and resources for mutual growth.\n",
            "\n",
            "5. **Customer Feedback Loop**: Establish a feedback loop with customers to gather insights on product features and user experience. Continuous feedback will help in refining products to meet evolving customer needs and stay competitive in the market.\n",
            "\n",
            "By implementing these recommendations, X-Point can strengthen its position in the Worktech sector, drive innovation, and achieve sustainable growth while meeting its objectives in ESG expertise and agile product management.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-a781a71310a4>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\033[31m\\r\\nPrompt: \\033[0m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "#if len(sys.argv) > 1:\n",
        " #   prompt = sys.argv[1]\n",
        "\n",
        "\n",
        "#while True:\n",
        " #   if not prompt:\n",
        "  #      prompt = input(\"\\033[31m\\r\\nPrompt: \\033[0m\")\n",
        "   # if prompt in ['quit', 'q', 'exit']:\n",
        "    #    sys.exit()\n",
        "\n",
        "   # prompt = prompt\n",
        "   # print(agent.run(prompt))\n",
        "   # prompt = None\n",
        "\n",
        "#print(agent.run(prompt))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if len(sys.argv) > 1:\n",
        "    prompt = sys.argv[1]\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "    if not prompt:\n",
        "        prompt = input(\"\\033[31m\\r\\nPrompt: \\033[0m\")\n",
        "    if prompt in ['quit', 'q', 'exit']:\n",
        "        sys.exit()\n",
        "\n",
        "    prompt = prompt+\" \"+post_prompt\n",
        "    agent_executor({\"input\": prompt})\n",
        "    prompt = None\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCBDWVESXpB6nQkxRB5jLK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}